---
title: Concepts
---

Exploring some of the key concepts to understand when using Langtrace AI for your traces.

### Span

A Span in LLM monitoring is a specific operation or task, like processing a request, within the system. It records the operation's start, end, and additional data to help in performance analysis and troubleshooting.

### Trace

A Trace represents the entire journey of a request through the LLM system, composed of multiple spans. It provides a complete picture of all operations involved in processing the request, aiding in system performance evaluation and issue identification.

![traces](/images/trace.png)

### Metric

A Metric is a quantifiable measure used to evaluate the performance and effectiveness of an LLM. Common metrics include latency, accuracy, precision, recall, and F1 score for tasks like classification. Metrics provide objective criteria for assessing the model's capabilities and monitoring its performance over time.

![traces](/images/metrics.png)

### Project

A Project in monitoring terms is a logical grouping of traces that correspond to a specific application or service. It acts as a container, organizing traces to simplify management and analysis. Within a single project, you can monitor various aspects of the application's performance and behavior through its traces. Having multiple projects allows for clear separation and focused monitoring of different applications or services within an organization.

![traces](/images/SCR-20240402-lwkd-2.png)

### Dataset

A Dataset refers to a structured collection of data used to train, test, or validate a Large Language Model (LLM). In the context of LLMs, datasets typically consist of text entries, but they can also include other data types like images or structured data, depending on the model's purpose. Datasets are crucial for developing and refining LLMs, as they provide the raw material on which these models learn and improve.

![traces](/images/dataset.png)

### Evaluation

Evaluation in LLM monitoring is the process of assessing the model's performance and effectiveness. This involves using specific tasks or benchmarks to test the LLM's abilities, such as its accuracy, coherence, and relevance of generated text. Evaluation helps in understanding how well the model meets the desired outcomes and in identifying areas for improvement.

![traces](/images/evaluation.png)
